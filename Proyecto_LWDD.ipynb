{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto LWDD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr0tbYPzhTaE"
      },
      "source": [
        "# Import libraries to run the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm1EIQczY3la"
      },
      "source": [
        "import sys\r\n",
        "!pip install -q rdflib networkx matplotlib\r\n",
        "!{sys.executable} -m pip install rdflib networkx matplotlib --user\r\n",
        "import pandas as pd #for handling csv and csv contents\r\n",
        "from rdflib import Graph, Literal, RDF,RDFS, URIRef, Namespace #basic RDF handling\r\n",
        "from rdflib.namespace import FOAF , XSD #most common namespaces\r\n",
        "import urllib.parse #for parsing strings to URI's"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7vI2wf-hflu"
      },
      "source": [
        "# Load anime.csv data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YbwK7NkkqcP"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/csepulvedaa/Proyecto-CC7220-G12/main/anime.csv'\r\n",
        "df=pd.read_csv(url,sep=\",\",quotechar='\"')\r\n",
        "# df # uncomment to check for contents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BHEEJJRhhW1"
      },
      "source": [
        "# Load rating.csv data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmrsLz_rvSE"
      },
      "source": [
        "url2 = 'https://raw.githubusercontent.com/csepulvedaa/Proyecto-CC7220-G12/main/rating.csv'\r\n",
        "df2=pd.read_csv(url2,sep=\",\",quotechar='\"')\r\n",
        "df2_filtered = df2[df2.rating > -1]\r\n",
        "df2_mean = df.groupby(['anime_id'], as_index=False)['rating'].mean()\r\n",
        "# df2  # uncomment to check for contents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s12KPhAvhq50"
      },
      "source": [
        "# Main code to transform data\r\n",
        "### Auxiliar function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44yqbMGbvicQ"
      },
      "source": [
        "# Aux function to get values from df2_mean\r\n",
        "def get_user_mean_rate(id):\r\n",
        "    try:\r\n",
        "        id = int(id)\r\n",
        "        return df2_mean.iat[id,1]\r\n",
        "    except:\r\n",
        "        return -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SWAap0Yh90x"
      },
      "source": [
        "### Define triples for the rdf graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK9N9Raa7B1s"
      },
      "source": [
        "g = Graph()\r\n",
        "schema_path = 'http://schema.org/'  # Paths to uri\r\n",
        "anime_path = 'http://myanimelist.net/anime/'\r\n",
        "schema = Namespace(schema_path)  # Prefix declaration\r\n",
        "anime = Namespace(anime_path)\r\n",
        "\r\n",
        "i=0\r\n",
        "genre_list = []  # Save distinct genres for column 'genre'\r\n",
        "type_list = []  # Save dictinct types for column 'type'\r\n",
        "\r\n",
        "for index, row in df.iterrows():\r\n",
        "    g.add((URIRef(anime + str(row['anime_id'])), RDF.type, URIRef(schema + 'Anime')))\r\n",
        "    g.add((URIRef(anime + str(row['anime_id'])), URIRef(anime + 'name'), Literal(row['name'], datatype=XSD.string)))\r\n",
        "    \r\n",
        "    if not pd.isna(row['episodes']):\r\n",
        "        g.add((URIRef(anime + str(row['anime_id'])), URIRef(schema + 'episodes'), Literal(row['episodes'], datatype=XSD.integer)))\r\n",
        "    if not pd.isna(row['rating']):\r\n",
        "        g.add((URIRef(anime + str(row['anime_id'])), URIRef(schema + 'rating'), Literal(row['rating'], datatype=XSD.integer)))\r\n",
        "    if not pd.isna(row['members']):\r\n",
        "        g.add((URIRef(anime + str(row['anime_id'])), URIRef(schema + 'members'), Literal(row['members'], datatype=XSD.integer)))\r\n",
        "    if not pd.isna(row['type']):\r\n",
        "        g.add((URIRef(anime + str(row['anime_id'])), URIRef(schema + 'type'), URIRef(schema + str(row['type']))))\r\n",
        "    \r\n",
        "    # Join rating dataset\r\n",
        "    user_mean_rate = get_user_mean_rate(row['anime_id'])\r\n",
        "    if user_mean_rate > 0:\r\n",
        "        g.add((URIRef(anime + str(row['anime_id'])), URIRef(schema + 'user_mean_rate'), Literal(user_mean_rate, datatype=XSD.double)))\r\n",
        "    \r\n",
        "    if not pd.isna(row['genre']) and row['type'] not in type_list:\r\n",
        "        type_list.append(row['type'])\r\n",
        "    \r\n",
        "    if not pd.isna(row['genre']):\r\n",
        "        genres = row['genre'].split(',')  # Split to get every genre for an anime\r\n",
        "        for a_genre in genres:\r\n",
        "            genre = a_genre.strip()  # deal with blank spaces after split\r\n",
        "            genre = genre.replace(' ','_')  # deal with spaces between words\r\n",
        "            g.add((URIRef(anime + str(row['anime_id'])), URIRef(schema + 'genre'), URIRef(schema + str(genre))))\r\n",
        "            if genre not in genre_list:\r\n",
        "                genre_list.append(genre)\r\n",
        "\r\n",
        "for a_genre in genre_list:  # Add Genre \r\n",
        "    g.add((URIRef(schema + str(a_genre)), RDF.type, URIRef(schema + 'Genre')))\r\n",
        "\r\n",
        "for a_type in type_list:  # Add Type \r\n",
        "    g.add((URIRef(schema + str(a_type)), RDF.type, URIRef(schema + 'Type')))\r\n",
        "\r\n",
        "g.serialize(destination='output.txt', format='turtle')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFLB-OJbiLEy"
      },
      "source": [
        "# Result\r\n",
        "The output is an archive that contains the data with the RDF structure. Then its ready to make queries on a sparQL endpoint."
      ]
    }
  ]
}